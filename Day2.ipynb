{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.17"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteoalberti/Lectures_introML_Experis2020/blob/master/Day2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEnwnRhNRRyx"
      },
      "source": [
        "# **Welcome Again!**\n",
        "\n",
        "## Introduction to Machine Learning Pt.2\n",
        "\n",
        "\n",
        "\n",
        "## **Lecturer :** Matteo Alberti\n",
        "\n",
        "![](data:image/jpeg;base64,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)\n",
        "\n",
        "*Contacts :* https://www.linkedin.com/in/matteo-alberti-170493/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sibE43BKRVLV"
      },
      "source": [
        "## Introduction to Supervised and Unsupervised Machine Learning\n",
        "\n",
        "![](https://www.diegocalvo.es/wp-content/uploads/2018/09/machine-learning-classification.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VraWNaq_RdBU"
      },
      "source": [
        "## What if ..\n",
        "\n",
        "$y=f(x)$\n",
        "\n",
        "### y is not a quantitative variable?\n",
        "\n",
        "![](https://whataftercollege.com/wp-content/uploads/2020/05/Classification-of-Machine-Learning.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HVXpqQxRs9D"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "A solution for classification is logistic regression. Instead of fitting a straight line or hyperplane, the logistic regression model uses the logistic function to squeeze the output of a linear equation between 0 and 1. The logistic function is defined as:\n",
        "\n",
        "$$logistic(η) = \\frac{1}{1+ exp(-η)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIt0TRdHnjCz"
      },
      "source": [
        "![](https://www.graphpad.com/guides/prism/8/curve-fitting/images/hmfile_hash_38a8acae.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa9iLkBSnp7h"
      },
      "source": [
        " In the linear regression model, we have modelled the relationship between outcome and features with a linear equation:\n",
        "\n",
        " $yhat = alfa + beta_1 * x_1 + beta_2 * x_2 + … + beta_p * x_p + error$\n",
        "\n",
        "\n",
        " For classification, we prefer probabilities between 0 and 1\n",
        "\n",
        " $$logistic(η) = \\frac{1}{1+ exp(-(alfa + beta_1 * x_1 + beta_2 * x_2 + … + beta_p * x_p + error) )}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOSCehzwoqUp"
      },
      "source": [
        "# Metrics for binary classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zya01K73p5ho"
      },
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "Confusion Matrix is a tool to determine the performance of classifier. It contains information about actual and predicted classifications. The below table shows confusion matrix of two-class, spam and non-spam classifier.\n",
        "\n",
        "![](https://glassboxmedicine.files.wordpress.com/2019/02/confusion-matrix.png?w=816)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elyC9h5aqs__"
      },
      "source": [
        "### We can develop several metrics based on CM\n",
        "\n",
        "**Sensitivity** is also referred as True Positive Rate or Recall. It is measure of positive examples labeled as positive by classifier. It should be higher. For instance, proportion of emails which are spam among all spam emails.  \n",
        "\n",
        "$$TP/(TP+FP)$$\n",
        "\n",
        "*Example* : SPAM detection, Breast Cancer detection, ect ect\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaXm-5GvrglB"
      },
      "source": [
        "**Specificity** is also know as True Negative Rate. It is measure of negative examples labeled as negative by classifier. \n",
        "\n",
        "$$TN/(TN+FN)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ref1_hgr4Jw"
      },
      "source": [
        "**Precision** is ratio of total number of correctly classified positive examples and the total number of predicted positive examples\n",
        "\n",
        "\n",
        "$$TP/(TP+FN)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH5Qc322sJOW"
      },
      "source": [
        "**Accuracy** \n",
        "\n",
        "$$(TP+TN)/(ALL)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qJxjaH7qVWq"
      },
      "source": [
        "## Summary \n",
        "\n",
        "![](https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hermyPaJscB6"
      },
      "source": [
        "**F1 score** : weighted average of the recall (sensitivity) and precision.\n",
        "\n",
        "$$F1_{score} = 2* \\frac{Precision * Recall}{Precision + Recall}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfLY36nRtANp"
      },
      "source": [
        "## ROC Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtHMvCH9tDfT"
      },
      "source": [
        "**An ROC curve (or receiver operating characteristic curve) is a plot that summarizes the performance of a binary classification model on the positive class.**\n",
        "\n",
        "*AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes.*\n",
        "\n",
        "The x-axis : **FPr** \n",
        "\n",
        "The y-axis : **TPr**\n",
        "\n",
        "ROC Curve: Plot of False Positive Rate (x) vs. True Positive Rate (y).\n",
        "\n",
        "The **true positive rate** is a fraction calculated as the total number of true positive predictions divided by the sum of the true positives and the false negatives (e.g. all examples in the positive class). The true positive rate is referred to as the **sensitivity** or the **recall**.\n",
        "\n",
        "**TruePositiveRate = TruePositives / (TruePositives + False Negatives)**\n",
        "\n",
        "The **false positive** rate is calculated as the total number of false positive predictions divided by the sum of the false positives and true negatives (e.g. all examples in the negative class).\n",
        "\n",
        "**FalsePositiveRate = FalsePositives / (FalsePositives + TrueNegatives)**\n",
        "\n",
        "We can think of the plot as the fraction of correct predictions for the positive class (y-axis) versus the fraction of errors for the negative class (x-axis).\n",
        "\n",
        "![](https://els-jbs-prod-cdn.jbs.elsevierhealth.com/cms/attachment/36cdb4ec-0c7d-48cb-9a4d-7cb463f8b7c3/gr1.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKCba-QNorT-"
      },
      "source": [
        "# Imbalanced Classification\n",
        "\n",
        "![](https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/QFE3K6B2QE4I5FJDTVOVGC7M5M.png)\n",
        "\n",
        "\n",
        "\n",
        "For imbalanced classification problems, the majority class is typically referred to as the negative outcome (e.g. such as “no change” or “negative test result“), and the minority class is typically referred to as the positive outcome (e.g. “change” or “positive test result“)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVnsMzkooVSv"
      },
      "source": [
        "# Multi Class Classification\n",
        "\n",
        " A classification task with more than two classes\n",
        "\n",
        " We have to adapt our *Logistic Function* to a new tasks . . . multi-class classification\n",
        "\n",
        " **Multinomial Logistic Regression** \n",
        "\n",
        "It uses **softmax function** instead of the sigmoid function the cross entropy loss function. **Softmax is a generalization of the sigmoid function.**\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/bdc1f8eaa8064d15893f1ba6426f20ff8e7149c5)\n",
        "\n",
        "\n",
        "*Steps :*\n",
        "\n",
        "- Raise e (the mathematical constant) to the power of each of those numbers.\n",
        "- Sum up all the exponentials (powers of ee). This result is the denominator.\n",
        "- Use each number’s exponential as its numerator.\n",
        "- $Probability=\\frac{Numerator}{Denominator}$\n",
        "\n",
        "\n",
        "The softmax function squashes all values to the range [0,1] and the sum of the elements is 1.\n",
        "\n",
        "\n",
        "*Example* : \n",
        "\n",
        "Given : -1, 0, 3, 5\n",
        "\n",
        "*We calculate Denominator :* $e^{-1}+e^{0} + e^{3} + e^{5}$ = 169.87\n",
        "\n",
        "*We calculate each Numerator $e^{x}$: * $e^{-1}=0.368, e^{}=1 . . . $\n",
        "\n",
        "*We calculate single probabilities :* $ P( \\frac{e^{x}}{{Denominator}})$ : 0.368/169.87 = 0.002, 1/169.87= 0.006 . . \n",
        "\n",
        "**Bigger x : bigger Probability**\n",
        "\n",
        "*Try to calculate all values probabilities and sum each other, what is the final number?*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqGS96r1B2Kf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlN5gTcleqjW"
      },
      "source": [
        "# Fuck paper and pen, use numpy!\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def softmax(xs):\n",
        "    return np.exp(xs) / sum(np.exp(xs))\n",
        "\n",
        "xs = np.array([####])\n",
        "print(softmax(xs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB5Cg1KjquAT"
      },
      "source": [
        "## Confusion Matrix for multi-class classification\n",
        "\n",
        "\n",
        "![](https://miro.medium.com/max/2228/1*yH2SM0DIUQlEiveK42NnBg.png)\n",
        "\n",
        "\n",
        "\n",
        "### Any problem with that? discuss together!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6zzeRGOwl_w"
      },
      "source": [
        "# Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ-sP6xvwmJ5"
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3tWxJL9weeb"
      },
      "source": [
        "### Wine quality Dataset\n",
        "\n",
        "- Fixed acidity\n",
        " -Volatile acidity\n",
        "- Citric acid\n",
        "- Residual sugar\n",
        "- Chlorides\n",
        "- Free sulfur dioxide\n",
        "- Total sulfur dioxide\n",
        "- Density\n",
        "- pH\n",
        "- Sulfates\n",
        "- Alcohol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGsrtJlmet-k"
      },
      "source": [
        "df_wine = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', delimiter=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkJodmqzLVvg",
        "outputId": "ea41686a-6fda-43d7-b920-b6e59041d6fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# show dataset first 10 rows\n",
        "\n",
        "df_wine.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.0010</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.9951</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.9951</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.16</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.045</td>\n",
              "      <td>30.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0.9949</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.47</td>\n",
              "      <td>9.6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.0010</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.044</td>\n",
              "      <td>28.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0.9938</td>\n",
              "      <td>3.22</td>\n",
              "      <td>0.45</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.0              0.27         0.36  ...       0.45      8.8        6\n",
              "1            6.3              0.30         0.34  ...       0.49      9.5        6\n",
              "2            8.1              0.28         0.40  ...       0.44     10.1        6\n",
              "3            7.2              0.23         0.32  ...       0.40      9.9        6\n",
              "4            7.2              0.23         0.32  ...       0.40      9.9        6\n",
              "5            8.1              0.28         0.40  ...       0.44     10.1        6\n",
              "6            6.2              0.32         0.16  ...       0.47      9.6        6\n",
              "7            7.0              0.27         0.36  ...       0.45      8.8        6\n",
              "8            6.3              0.30         0.34  ...       0.49      9.5        6\n",
              "9            8.1              0.22         0.43  ...       0.45     11.0        6\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTx4QDuXGJqm"
      },
      "source": [
        "# show dataset last 10 rows\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp5W8byexYs3"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxb6aCnVMtUU"
      },
      "source": [
        "# how many classes has the target?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWmOX3gQxS2s"
      },
      "source": [
        "# check df dimensions, how many rows? columns?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "098kg_wCxEVX"
      },
      "source": [
        "# check how big is our dataset in KB/MB/GB\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6a4BG1puSVJ"
      },
      "source": [
        "# Describe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkP69rRAO_gX"
      },
      "source": [
        "# missing values?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KGyEwH1Pu10"
      },
      "source": [
        "# correlation matrix\n",
        "\n",
        "\n",
        "# which variables are the most correlated?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW_PpLRkq4UN"
      },
      "source": [
        "df_wine_bkp = df_wine.copy()\n",
        "\n",
        "# do it again only with most relevant variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeKtE2oDq_Wz"
      },
      "source": [
        "## Now the hard part : TO SUPERVISED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc7jc-omxY1F"
      },
      "source": [
        "# EXTRA : barplot of quality.  TIPS : use sns.countplot(dataset['name of the column'])\n",
        "\n",
        "sns.countplot(df_wine['quality'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNsPk99arknI"
      },
      "source": [
        "## We will come back soon . . . ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrwcwl-lR9AO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGo5EqgRSgeE",
        "outputId": "67142ece-a827-4543-9f42-15129ce88dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Data Splitting. TIPS : use train_test_split function\n",
        "\n",
        "# - 70/30\n",
        "# - add shuffle=True\n",
        "\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(df_wine.drop(['category'], axis=1),df_wine['category'],test_size=0.30, shuffle=True)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3428, 11) (1470, 11) (3428,) (1470,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlSlibmotjBP"
      },
      "source": [
        "# Are we ready for that??\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48k9V5Z8VTZZ",
        "outputId": "a25362d2-81e9-4dda-b199-d6b917266bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "%%time\n",
        "log_regressor=LogisticRegression( multi_class='multinomial') \n",
        "\n",
        "# FIT\n",
        "\n",
        "log_regressor.fit(###,###)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25.6 ms, sys: 0 ns, total: 25.6 ms\n",
            "Wall time: 26.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYPacrMqx5gs"
      },
      "source": [
        "# Score!\n",
        "\n",
        "score=log_regressor.score(###,###)\n",
        "print('accuracy = {}'.format(score))\n",
        "\n",
        "# Write the accuracy formula TP, TN, ect ect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF38wW5uXMmz"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "y_pred1 = log_regressor.predict(###)\n",
        "    \n",
        "print(classification_report(###, ###))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl2QawYlhtNF"
      },
      "source": [
        "# features importance\n",
        "\n",
        "importance = log_regressor.coef_\n",
        "\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance[0]):\n",
        "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "plt.bar([x for x in range(len(importance[0]))], importance[0])\n",
        "plt.show()\n",
        "\n",
        "print(df_wine.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VviUd6d-xcPV"
      },
      "source": [
        "# STOP!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7LNy3BlxO7H"
      },
      "source": [
        "## Learn how to Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scchrRCu2m_c"
      },
      "source": [
        "# define which features\n",
        "numeric_features = ['fixed acidity', 'volatile acidity', 'citric acid']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBDtsG462GvU",
        "outputId": "f44df6e7-4bdd-448a-8693-48a18208f8c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_wine2 = df_wine[['fixed acidity', 'volatile acidity', 'citric acid', 'category']]\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(df_wine2.drop(['category'], axis=1),df_wine2['category'],test_size=0.30, shuffle=True)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3428, 3) (1470, 3) (3428,) (1470,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNkcjFw7zui7"
      },
      "source": [
        "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "                  ('num', numeric_transformer, numeric_features)])\n",
        "\n",
        "\n",
        "lor = LogisticRegression()\n",
        "\n",
        "clf = Pipeline([('preprocessor', preprocessor), \n",
        "                ('lor',lor)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv32p8wBvi4h"
      },
      "source": [
        "clf.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7GHbxn6vjsE"
      },
      "source": [
        "clf.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGY9wBaP9x9V"
      },
      "source": [
        "# This is a real exercise . . . take your time ;)\n",
        "\n",
        "    I'd like to plot ROC curve for my model. After some online checks I found the following code with an error. What happened? How can I solve? \n",
        "\n",
        "*TIPS : questo non è un esercizio semplice. Cio che vorrei mettere in mostra è la reale esigenza di capire cosa si stia scrivendo in uno scenario reale e comune. INIZIATE DAL RESTO E LASCIATE QUESTO PER ULTIMO*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZWVj96b3_fY"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "roc = metrics.roc_curve(Y_test,clf.predict_proba(X_test)[:,1])\n",
        "pr  = precision_recall_curve(Y_test,clf.predict_proba(X_test)[:,1])\n",
        "\n",
        "\n",
        "\n",
        "f = plt.figure(figsize=(20,7))\n",
        "ax = f.add_subplot(121)\n",
        "ax.plot(roc[0],roc[1])\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_title('ROC Curve')\n",
        "ax.grid(which='both')\n",
        "ax = f.add_subplot(122)\n",
        "ax.plot(pr[1],pr[0])\n",
        "ax.set_ylabel('Precision')\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_title('PR-curve')\n",
        "ax.grid(which='both')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeWZnKDNWjlz"
      },
      "source": [
        "# Decision Tree \n",
        "\n",
        "Classification and Regression Trees or CART for short is a term introduced by Leo Breiman to refer to Decision Tree algorithms that can be used for classification or regression predictive modeling problems.\n",
        "\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/688/0*pb-1ufHK-OmR8k7r.png)\n",
        "\n",
        "- Decision Trees (DTs) are a **non-parametric** supervised learning method used for classification and regression.\n",
        "\n",
        "\n",
        "*What does it means??*\n",
        "\n",
        "    EXPLAIN together:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS9bv6G5B2Mj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWkODQ_EB2Mk"
      },
      "source": [
        "**What about features and preprocessing?**\n",
        "\n",
        "- Feature values are preferred to be categorical. If the values are continuous then they are discretized prior to building the model.\n",
        "\n",
        "- Does not require special preprocessing of:\n",
        "    - missing data\n",
        "    - outliers\n",
        "    \n",
        "Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTG136qFB2Ml"
      },
      "source": [
        "## Splitting\n",
        "\n",
        "\n",
        "- The process of partitioning the data set into subsets\n",
        "\n",
        "![](https://cdn.educba.com/academy/wp-content/uploads/2019/05/splitting.png)\n",
        "\n",
        "\n",
        "## Pruning\n",
        "\n",
        "- Pruning is the process of reducing the size of the tree by turning some branch nodes into leaf nodes\n",
        "\n",
        "![](https://www.cs.cmu.edu/~bhiksha/courses/10-601/decisiontrees/DTprune.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CYWpnZtB2Ml"
      },
      "source": [
        "## How do we split?\n",
        "\n",
        "\n",
        "### CART \n",
        "\n",
        "(Classification and Regression Tree) uses the Gini index method to create split points.\n",
        "\n",
        "### GINI INDEX\n",
        "\n",
        "Gini Index, also known as Gini impurity, calculates the amount of probability of a specific feature that is classified incorrectly when selected randomly. \n",
        "\n",
        "\n",
        "$$ Gini = 1 - \\sum_jp_j^2 $$\n",
        "\n",
        "\n",
        "*If all the elements are linked with a single class then it can be called pure.*\n",
        "\n",
        "    total students = 10\n",
        "    \n",
        "    \n",
        "    Example (1):    \n",
        "    \n",
        "    good students = 10\n",
        "    bad students = 0 \n",
        "    \n",
        "$$ Gini = 1 - [ P(goodstudents)^2 + P(badstudents)^2] = 1 - (1^2 +0) = 0 $$\n",
        "\n",
        "\n",
        "    Example (2):\n",
        "    \n",
        "    good students = 5\n",
        "    bad students = 5\n",
        "    \n",
        "$$ Gini = 1 - [ P(goodstudents)^2 + P(badstudents)^2] = 1 - (0.5^2 +0.5^2) = 0.5 $$\n",
        "\n",
        "    Example (3):\n",
        "\n",
        "    good students = 7\n",
        "    bad students = 3\n",
        "    \n",
        "$$ Gini = 1 - [ P(goodstudents)^2 + P(badstudents)^2] = 1 - (0.75^2 +0.25^2) = 0.375 $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-16T16:40:47.506285Z",
          "start_time": "2020-11-16T16:40:47.371807Z"
        },
        "id": "4nPVTq08B2Mm",
        "outputId": "b915fb94-41ce-445b-a96a-a0ea29d922c8"
      },
      "source": [
        "#Numerical example :\n",
        "\n",
        "\n",
        "def gini(a,b):\n",
        "    a1 = (a/(a+b))**2\n",
        "    b1 = (b/(a+b))**2\n",
        "    return 1 - (a1 + b1)\n",
        "\n",
        "\n",
        "gini_list = []\n",
        "blue_list = []\n",
        "red_list = []\n",
        "blue_prob_list = []\n",
        "#Looping Gini function on random blue and red float amounts\n",
        "for x in range (10000):\n",
        "    blue = np.random.uniform(0, 4)\n",
        "    red = abs(4-blue)\n",
        "    a = gini(red,blue)\n",
        "    b = blue/(blue+red)\n",
        "    gini_list.append(a)\n",
        "    blue_list.append(blue)\n",
        "    red_list.append(red)\n",
        "    blue_prob_list.append(b)\n",
        "    \n",
        "df = pd.DataFrame({\"Blue\": blue_list, \"Red\": red_list,\"Gini Score\": gini_list, \"Probability of Blue\": blue_prob_list})\n",
        "df = df[[\"Red\", \"Blue\", \"Probability of Blue\", \"Gini Score\"]]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Red</th>\n",
              "      <th>Blue</th>\n",
              "      <th>Probability of Blue</th>\n",
              "      <th>Gini Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.755845</td>\n",
              "      <td>2.244155</td>\n",
              "      <td>0.561039</td>\n",
              "      <td>0.492549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.473984</td>\n",
              "      <td>0.526016</td>\n",
              "      <td>0.131504</td>\n",
              "      <td>0.228421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.991192</td>\n",
              "      <td>2.008808</td>\n",
              "      <td>0.502202</td>\n",
              "      <td>0.499990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.155247</td>\n",
              "      <td>0.844753</td>\n",
              "      <td>0.211188</td>\n",
              "      <td>0.333176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.832569</td>\n",
              "      <td>2.167431</td>\n",
              "      <td>0.541858</td>\n",
              "      <td>0.496496</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Red      Blue  Probability of Blue  Gini Score\n",
              "0  1.755845  2.244155             0.561039    0.492549\n",
              "1  3.473984  0.526016             0.131504    0.228421\n",
              "2  1.991192  2.008808             0.502202    0.499990\n",
              "3  3.155247  0.844753             0.211188    0.333176\n",
              "4  1.832569  2.167431             0.541858    0.496496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-16T16:43:07.751962Z",
          "start_time": "2020-11-16T16:43:07.325972Z"
        },
        "id": "TpClk065B2Ms",
        "outputId": "3edeef8b-533d-49eb-ff86-78ef94225b47"
      },
      "source": [
        "plt.scatter(blue_prob_list,gini_list)\n",
        "plt.xlabel('Probability of Blue Gumball %')\n",
        "plt.ylabel('Gini')\n",
        "plt.title('Gini Curve')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2c3rmo4B2Mz"
      },
      "source": [
        "### How can we interpret the following picture?\n",
        "\n",
        "\n",
        "*Analogue to gini one*\n",
        "\n",
        "![](https://miro.medium.com/max/500/1*M15RZMSk8nGEyOnD8haF-A.png)\n",
        "\n",
        "\n",
        "Where :\n",
        "\n",
        "- The x-axis measures the proportion of data points belonging to the positive class in each bubble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ycu2Z0PB2Mz"
      },
      "source": [
        "### INFORMATION ENTROPY\n",
        "\n",
        "\n",
        "*This will be a bit more complex*\n",
        "\n",
        "$$ Entropy = - \\sum_j p_j * log_2(p_j) $$\n",
        "\n",
        "\n",
        "    Example (1) = 0 / (2)=1 \n",
        "    \n",
        "    (3)\n",
        "    \n",
        "\n",
        "$$ Entr = [(3/10)* log_2(3/10)]-[(7/10)* log_2(7/10)] = 0.811 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF1D5SRnB2M0"
      },
      "source": [
        "there are several ways to split : Entropy,\n",
        "Information gain,\n",
        "Gini index,\n",
        "Gain Ratio,\n",
        "Reduction in Variance\n",
        "Chi-Square"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF4PYtT9B2M0"
      },
      "source": [
        "## Summarize\n",
        "\n",
        "\n",
        "- It begins with the original set S as the root node.\n",
        "\n",
        "- On each iteration of the algorithm, it iterates through the very unused attribute of the set S and calculates Entropy(H) and Information gain(IG) of this attribute.\n",
        "\n",
        "- It then selects the attribute which has the smallest Entropy or Largest Information gain.\n",
        "\n",
        "- The set S is then split by the selected attribute to produce a subset of the data.\n",
        "\n",
        "- The algorithm continues to recur on each subset, considering only attributes never selected before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klq1ImC5B2M1"
      },
      "source": [
        "## Ok . . . let's come back to our original task!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbrcaEGoyGS8"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DT_class = DecisionTreeClassifier(random_state=1) #unecessary\n",
        "\n",
        "DT_class.fit(X_train, Y_train)\n",
        "\n",
        "y_pred1 = DT_class.predict(X_test)\n",
        "print(classification_report(Y_test, y_pred1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jKRpFxbB2M7"
      },
      "source": [
        "## Which is better Linear or tree-based models?\n",
        " \n",
        "*Well, it depends on the kind of problem you are solving.*\n",
        "\n",
        "- If the relationship between dependent & independent variables is well approximated by a linear model, linear regression will outperform the tree-based model.\n",
        "- If there is a high non-linearity & complex relationship between dependent & independent variables, a tree model will outperform a classical regression method.\n",
        "- If you need to build a model that is easy to explain to people, a decision tree model will always do better than a linear model. Decision tree models are even simpler to interpret than linear regression!\n",
        "- Missing data? Outliers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VmlGqEjaKMJ"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "Random forests are an ensemble learning technique that builds off of decision trees.\n",
        "\n",
        "***Ensemble methods**, which combines several decision trees to produce better predictive performance than utilizing a single decision tree. The main principle behind the ensemble model is that a group of weak learners come together to form a strong learner.*\n",
        "\n",
        "![](https://www.researchgate.net/profile/Evaldas_Vaiciukynas/publication/301638643/figure/fig1/AS:355471899807744@1461762513154/Architecture-of-the-random-forest-model.png)\n",
        "\n",
        "\n",
        "### Why Random?\n",
        "\n",
        "Two key concepts that give it the name random:\n",
        "\n",
        "- A random sampling of training data set when building trees.\n",
        "  **(do you remember anything?)**\n",
        "\n",
        "- Random subsets of features considered when splitting nodes.\n",
        "\n",
        "\n",
        "\n",
        "We'll not discuss about :\n",
        "\n",
        "- Bagging\n",
        "- Boosting\n",
        "\n",
        "\n",
        "I'll give to you some material if you want to know more about this!\n",
        "\n",
        "We'll say that genereally speaking we would reduce the variance of a decision tree\n",
        "\n",
        "- Random sub-set of data\n",
        "- Random sub-set of features with replacement\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-9gahCTyGP3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF_class = RandomForestClassifier(random_state=1)\n",
        "\n",
        "RF_class.fit(X_train, Y_train)\n",
        "\n",
        "y_pred2 = RF_class.predict(X_test)\n",
        "print(classification_report(Y_test, y_pred2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYQ5Rm5nhgcg",
        "outputId": "ff528ba3-47e4-4035-8471-80a5d484f000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Interested in the complex version with K-fold and grid search?\n",
        "\"\"\"\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = RandomForestClassifier(random_state=2018, oob_score=True)\n",
        "param_dist = {\"n_estimators\": [50, 100, 150, 200, 250],\n",
        "              'min_samples_leaf': [1, 2, 4]}\n",
        "rfc_gs = GridSearchCV(clf, param_grid=param_dist, scoring='accuracy', cv=5)\n",
        "rfc_gs.fit(X_train, Y_train)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom sklearn.model_selection import StratifiedKFold\\nfrom sklearn.model_selection import GridSearchCV\\n\\nclf = RandomForestClassifier(random_state=2018, oob_score=True)\\nparam_dist = {\"n_estimators\": [50, 100, 150, 200, 250],\\n              \\'min_samples_leaf\\': [1, 2, 4]}\\nrfc_gs = GridSearchCV(clf, param_grid=param_dist, scoring=\\'accuracy\\', cv=5)\\nrfc_gs.fit(X_train, Y_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdYfKabBbVF-"
      },
      "source": [
        "# XGBoost\n",
        "\n",
        "XGBoost provides a parallel tree boosting\n",
        "\n",
        "The two reasons to use XGBoost are also the two goals of the project:\n",
        "\n",
        "- Execution Speed.\n",
        "- Model Performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoXE6G6dyLEj"
      },
      "source": [
        "import xgboost as xgb\n",
        "XGB_class = xgb.XGBClassifier(random_state=1)\n",
        "\n",
        "XGB_class.fit(X_train, Y_train)\n",
        "\n",
        "y_pred5 = XGB_class.predict(X_test)\n",
        "print(classification_report(Y_test, y_pred5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUmZVoEYKBYV"
      },
      "source": [
        "## BREAK!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuoL9yrHB2NK"
      },
      "source": [
        "## Execises :\n",
        "\n",
        "You have several models :\n",
        "\n",
        "- Make a report explaining why you should chose a model instead of another based on metrics\n",
        "\n",
        "- are you able to plot a ROC Curve for each model? If yes, make a plot for each feature / model\n",
        "\n",
        "\n",
        "Extra :\n",
        "- look at pandas available datasets, load data (choose 1), and make some assumptions :\n",
        "    - which kind of ML is for? classification or regression?\n",
        "    - which models should I use?\n",
        "    - which model propably will perform better? why? (assumption, parametric or not, missing values? outliers? . . . )"
      ]
    }
  ]
}