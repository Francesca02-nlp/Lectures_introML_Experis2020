{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPecdalJ+5vVkiEDUlRJjH/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteoalberti/Lectures_machinelearningbasics_nomath/blob/master/Day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExXS3Y0zvYBm"
      },
      "source": [
        "# **Welcome!**\n",
        "\n",
        "## Introduction to Machine Learning\n",
        "\n",
        "\n",
        "\n",
        "## **Lecturer :** Matteo Alberti\n",
        "\n",
        "![](data:image/jpeg;base64,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)\n",
        "\n",
        "*Contacts :* https://www.linkedin.com/in/matteo-alberti-170493/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1q8Z0nT_lf2"
      },
      "source": [
        "## Introduction to Supervised and Unsupervised Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoLsN_emxn-X"
      },
      "source": [
        "![](https://www.diegocalvo.es/wp-content/uploads/2018/09/machine-learning-classification.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOK-Vucc_ejk"
      },
      "source": [
        "## Introduction to Linear and Logistic Regression Problem\n",
        "\n",
        "***Don't worry.. this will be the only formula that we'll use today***\n",
        "\n",
        "$y=f(x)$\n",
        "\n",
        "technically :\n",
        "\n",
        "$y=a + b*X + e$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLaDD2MfyJc5"
      },
      "source": [
        "The model is defined in terms of parameters called coefficients (beta), where there is one coefficient per input and an additional coefficient that provides the intercept or bias.\n",
        "\n",
        "For example, a problem with inputs X with m variables x1, x2, …, xm will have coefficients beta1, beta2, …, betam and beta0. A given input is predicted as the weighted sum of the inputs for the example and the coefficients.\n",
        "\n",
        "$yhat = alfa + beta_1 * x_1 + beta_2 * x_2 + … + beta_p * x_p + error$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5fgUZls2oTW"
      },
      "source": [
        "## An example of linear regression\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1200px-Linear_regression.svg.png)\n",
        "\n",
        "## what do we minimize?\n",
        "\n",
        "![](https://www.statisticshowto.com/wp-content/uploads/2015/03/residual.png)\n",
        "\n",
        "## When don't we have a linear relationship between variables?\n",
        "\n",
        "![](https://i.stack.imgur.com/uB7pm.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObSFqVcaADch"
      },
      "source": [
        "### Models too simple or too complex?\n",
        "\n",
        "![](https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdr9A87awnpw"
      },
      "source": [
        "### Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZotsUUqDwn01",
        "outputId": "392f866e-2316-4abe-92eb-13aaa9b612a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SD9SUXWvP1w"
      },
      "source": [
        "## From zero to Linear Regression \n",
        "\n",
        "- Data Loading\n",
        "\n",
        "- Data Preparation\n",
        "\n",
        "- Understand the task! Supervised, Unsupervised Learning?\n",
        "\n",
        "- Assumptions & Models\n",
        "\n",
        "- Metrics and Evaluation\n",
        "\n",
        "- Test yourself!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3mrHa7Lv5Mu"
      },
      "source": [
        "## First Exapled (GUIDED!)\n",
        "\n",
        "\n",
        "\n",
        "### Boston house dataset\n",
        "\n",
        "- CRIM: Per capita crime rate by town\n",
        "- ZN: Proportion of residential land zoned for lots over 25,000 sq. ft\n",
        "- INDUS: Proportion of non-retail business acres per town\n",
        "- CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "- NOX: Nitric oxide concentration (parts per 10 million)\n",
        "- RM: Average number of rooms per dwelling\n",
        "- AGE: Proportion of owner-occupied units built prior to 1940\n",
        "- DIS: Weighted distances to five Boston employment centers\n",
        "- RAD: Index of accessibility to radial highways\n",
        "- TAX: Full-value property tax rate per 10,000$$\n",
        "- PTRATIO: Pupil-teacher ratio by town\n",
        "- B: 1000(Bk — 0.63)², where Bk is the proportion of [people of African American descent] by town\n",
        "- LSTAT: Percentage of lower status of the population\n",
        "- MEDV: Median value of owner-occupied homes in $1000s\n",
        "\n",
        "### Translated\n",
        "\n",
        "- CRIM: tasso di criminalità pro capite per città\n",
        "- ZN: Proporzione di terreno residenziale suddiviso in zone per lotti superiori a 25.000 piedi quadrati\n",
        "- INDUS: proporzione di acri di attività commerciali non al dettaglio per città\n",
        "- CHAS: variabile fittizia Charles River (= 1 se il tratto confina con il fiume; 0 altrimenti)\n",
        "- NOX: concentrazione di ossido nitrico (parti per 10 milioni)\n",
        "- RM: numero medio di stanze per abitazione\n",
        "- ETÀ: Proporzione di unità abitate dai proprietari costruite prima del 1940\n",
        "- DIS: distanze ponderate da cinque centri per l'impiego di Boston\n",
        "- RAD: Indice di accessibilità alle autostrade radiali\n",
        "- TASSA: aliquota dell'imposta sulla proprietà a valore intero per 10.000 $$\n",
        "- PTRATIO: rapporto alunni-insegnanti per città\n",
        "- B: 1000 (Bk - 0.63) ², dove Bk è la proporzione di [persone di discendenza afroamericana] per città\n",
        "- LSTAT: percentuale di status inferiore della popolazione\n",
        "- MEDV: valore medio delle case occupate dai proprietari in $ 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xovd4vE_uUu0"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "boston_dataset = load_boston()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHJ9hjCNuZfZ",
        "outputId": "bbe55b7f-256f-498e-c292-042aeaa16ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(boston_dataset.keys())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRJiTH9nw_Lk",
        "outputId": "8a726df7-5342-4ecb-8b18-44e3fe66bd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
        "boston.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n",
              "2  0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n",
              "3  0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n",
              "4  0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt_z9JvXw_PB"
      },
      "source": [
        "# Which is the shape of our data?"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjUdWfGjw_VV"
      },
      "source": [
        "# What about the target?"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKAaIyUnxqzX"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "***what should I check about my data?***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfjxoLzqw_Sq"
      },
      "source": [
        "# There are any missing values? Look dropna function!\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOzXr5gQ4ci5"
      },
      "source": [
        "## EDA and Assumptions\n",
        "\n",
        "- When we use parametetric statistical models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHsJaUYw4cuD"
      },
      "source": [
        "\n",
        "# What is EDA? Exploratory Data Analysis, in this case : looking for the relationship of the target variable with other features.\n",
        "\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "sns.distplot(boston['MEDV'], bins=30)\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJCF5IYrztx7"
      },
      "source": [
        "*What Should I see from this plot??*\n",
        "\n",
        "- Data distribution!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJQFE8xd0lZ2"
      },
      "source": [
        "### Normal Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW5YGKjY0Jhn"
      },
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "# generate random numbers from N(0,1)\n",
        "data_normal = norm.rvs(size=10000,loc=0,scale=1)\n",
        "\n",
        "ax = sns.distplot(data_normal,\n",
        "                  bins=100,\n",
        "                  kde=True,\n",
        "                  color='green',\n",
        "                  hist_kws={\"linewidth\": 15,'alpha':1})\n",
        "\n",
        "ax.set(xlabel='Normal Distribution', ylabel='Frequency')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3tsNgr_1RAe"
      },
      "source": [
        "There are many other distributions...\n",
        "\n",
        "*Poisson, Binomial, Trinomial, Gamma, Exponential, Bernulli, . . . .*\n",
        "\n",
        "**But what does it mean converge into a distribution?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5bH2kdQysDw"
      },
      "source": [
        "# Bernulli Example\n",
        "\n",
        "# A Bernoulli distribution has only two possible outcomes, namely 1 (success) and 0 (failure)  | TESTA O CROCE!\n",
        "\n",
        "from scipy.stats import bernoulli\n",
        "data_bern = bernoulli.rvs(size=10,p=0.5)\n",
        "\n",
        "ax= sns.distplot(data_bern,\n",
        "                 kde=False,\n",
        "                 color=\"skyblue\",\n",
        "                 hist_kws={\"linewidth\": 15,'alpha':1})\n",
        "\n",
        "ax.set(xlabel='Bernoulli Distribution', ylabel='Frequency')\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twV2v7Ca1-Hs"
      },
      "source": [
        "Come back to our Boston Data set!\n",
        "\n",
        "\n",
        "***How can I check if normality is satisfied?***\n",
        "\n",
        "- Graphical tests\n",
        "- Shapiro Wilk test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQWxvjJi2ENE"
      },
      "source": [
        "from statsmodels.graphics.gofplots import qqplot\n",
        "\n",
        "qqplot(boston['MEDV'], line='s')\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2zNTwvp_FLe"
      },
      "source": [
        "### Which are our Outliers?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-hZ_90I-w4J"
      },
      "source": [
        "## Suggestion! But consider that creativity is your best tool!\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltHSjFY9_kGM"
      },
      "source": [
        "#### When you finish you can test with the above functions or use the a no-grafical test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VywnRRFo3oDa"
      },
      "source": [
        "# Shapiro-Wilk Test\n",
        "\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "stat, p = shapiro(boston['MEDV'])\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Sample looks Gaussian (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Sample does not look Gaussian (reject H0)')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kcko3KcBdTu"
      },
      "source": [
        "## Multi-collinearity\n",
        "\n",
        "Multicollinearity happens when independent variables in the regression model are highly correlated to each other. It makes it hard for interpretation of model and also creates overfitting problem.\n",
        "\n",
        "**But the main problem is the following :**\n",
        "\n",
        "- When independent variables are highly correlated, change in one variable would cause change to another and so the model results fluctuate significantly.\n",
        "\n",
        "\n",
        "### Correlation Matrix\n",
        "\n",
        "Next, we create a correlation matrix that measures the linear relationships between the variables. The correlation matrix can be formed by using the corr function from the pandas dataframe library. We will use the heatmap function from the seaborn library to plot the correlation matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGJk7OYYBdps"
      },
      "source": [
        "correlation_matrix = boston.corr().round(2)\n",
        "# annot = True to print the values inside the square\n",
        "sns.heatmap(data=correlation_matrix, annot=True)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgKZzKh2CLsp"
      },
      "source": [
        "*Which is the Correlation Matrix range?*\n",
        "\n",
        "- from :\n",
        "- to :\n",
        "\n",
        "\n",
        "*Which features will we select?*\n",
        "\n",
        "*Multi-Collinearity?*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxCKuGDLFVtJ"
      },
      "source": [
        "## Homoschedasticity\n",
        "\n",
        "![](https://miro.medium.com/max/700/1*V-ZwpBFum-jP710q_fyjBA.png)\n",
        "\n",
        "- Often occurs in those data sets which have a large range between the largest and the smallest observed values i.e. when there are outliers.\n",
        "- When model is not correctly specified.\n",
        "- If observations are mixed with different measures of scale.\n",
        "- When incorrect transformation of data is used to perform the regression.\n",
        "Skewness in the distribution of a regressor, and may be some other sources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wETLuaR_CMdC"
      },
      "source": [
        "### Show the final Dataframe with all the selected columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVY03Pk8CUXK"
      },
      "source": [
        "# select by name df=[[]] | select by .iloc func\n",
        "\n",
        "\n",
        "\n",
        "boston.head()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crfXpzjB6rwZ"
      },
      "source": [
        "## Data Splitting\n",
        "\n",
        "There are lots of ways to split our data and lots of packages\n",
        "\n",
        "- Divided manually\n",
        "- build-in function inside sklearn\n",
        "  - train_test_val\n",
        "  - . . . \n",
        "\n",
        "\n",
        "And also depend on data type / dataset size\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU6ewkcJ6r9A"
      },
      "source": [
        "import sklearn.model_selection as model_selection\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(boston[boston.columns[:-1]], boston[boston.columns[-1:]], train_size=0.65,test_size=0.35, random_state=101)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4gd7jHDDQ7O"
      },
      "source": [
        "print (\"Original: \", boston.shape, \"\\n\")\n",
        "\n",
        "print (\"X_train: \", X_train.shape)\n",
        "print (\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print (\"y_test: {} \\n \".format(y_test.shape))\n",
        "\n",
        "print (\"Reconstruct X : \", X_train.shape[0] + X_test.shape[0])\n",
        "\n",
        "# Check also Y"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EfpFrc3EUsL"
      },
      "source": [
        "### K-fold cross-validation\n",
        "\n",
        "![](https://static.packt-cdn.com/products/9781789617740/graphics/b04c27c5-7e3f-428a-9aa6-bb3ebcd3584c.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw8SHcfd9EtF"
      },
      "source": [
        "## Model Definition & Traning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhMGd4P39E29",
        "outputId": "fad28b8f-3ee8-4a96-8df5-fc5941390d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "%%time\n",
        "\n",
        "# Fitting the model\n",
        "boston_model = LinearRegression()\n",
        "boston_model.fit(X_train, y_train)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMjAji9O_OOo"
      },
      "source": [
        "### How do I evaluate my model?  P.s. look at .score funcion ok sklearn!\n",
        "\n",
        "# Returning the R^2 for the model\n",
        "boston_r2 = boston_model.score(X_test, y_test)\n",
        "print('R^2: {0}'.format(boston_r2))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmVxDrueHJAB"
      },
      "source": [
        "### We have lots of metrics of evaluation \n",
        "\n",
        "*Let me show you the most relevant*\n",
        "\n",
        "- Mean Squared Error**(MSE)**        \n",
        "\n",
        "$$ MSE = \\frac {\\sum (y - y_{hat})^2}{N} $$\n",
        "\n",
        "it penalizes even a small error which leads to over-estimation of how bad the model is\n",
        "\n",
        "- Root-Mean-Squared-Error**(RMSE)**\n",
        "\n",
        "$$ RMSE = \\sqrt \\frac {\\sum (y - y_{hat})^2}{N} $$\n",
        "\n",
        "This implies that RMSE is useful when large errors are undesired.\n",
        "\n",
        "- Mean-Absolute-Error**(MAE)**\n",
        "\n",
        "$$ MSE = \\frac {\\sum |y - y_{hat}|}{N} $$\n",
        "\n",
        "The MAE is more robust to outliers and does not penalize the errors as extremely as mse\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgieAXI1LXyV"
      },
      "source": [
        "\n",
        "- **R²** or Coefficient of Determination.\n",
        "\n",
        "*Question :* which is the range of $R^2$? Why?\n",
        "\n",
        "- **Adjusted R²**\n",
        "\n",
        "As $R^2$ but penalize too variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dbv4b_PMUtS"
      },
      "source": [
        "## Question from your manager : Which features are the most relevant?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q6_h9q7Moz_"
      },
      "source": [
        "importance = boston_model.coef_  ## What is .coef???\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance[0]):\n",
        "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "plt.bar([x for x in range(len(importance[0]))], importance[0])\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qlEIoS9TH1P"
      },
      "source": [
        "## Now.. Try to predict!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrgTfMknHq3p"
      },
      "source": [
        "# BREAK!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMtj-P02OLJN"
      },
      "source": [
        "Do yourself on another dataset!\n",
        "\n",
        "**Need a suggest?**\n",
        "\n",
        "- Try with : **load_diabetes**\n",
        "- Try with : **Kaggle**  : www.kaggle.com\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtvs3HM9OvcH"
      },
      "source": [
        "Do you want any good reference for learning in easy and good way?\n",
        "\n",
        "- https://machinelearningmastery.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuA7FJVUY-HU"
      },
      "source": [
        "# Or we can make it a bit more complex!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzv8GaKyY_Al"
      },
      "source": [
        "df_flights = pd.read_csv('https://raw.githubusercontent.com/ismayc/pnwflights14/master/data/flights.csv')\n",
        "\n",
        "df_flights.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz5gRNQWb258"
      },
      "source": [
        "## Repeat the above steps and answer to this :\n",
        "\n",
        "- how many years do we have? which function did you use?\n",
        "- can you make a pie or a bar plot?\n",
        "- missing values BY column \n",
        "  - How did you managed? \n",
        "\n",
        "- Linear Regression with all variables! Predict the expected arrived delay!\n",
        "  - Which is the main problem?\n",
        "  - Which score did you use?\n",
        "  - Explain your results"
      ]
    }
  ]
}